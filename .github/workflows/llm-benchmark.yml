name: LLM Benchmark

run-name: "${{ inputs.model_name }} - ${{ inputs.hardware }} - ${{ inputs.generation_gpus }}+${{ inputs.prefill_gpus }} - ${{ inputs.precision }} - ${{ inputs.speculation_tokens }} draft"

on:
  workflow_dispatch:
    inputs:
      model_name:
        description: 'Model name (e.g., DeepSeek-V3)'
        required: true
        type: string
      deployment:
        description: 'Deployment ID (e.g., accounts/pyroworks/deployments/xxx)'
        required: true
        type: string
      generation_gpus:
        description: 'Number of GPUs for generation (decode)'
        required: true
        type: number
        default: 8
      prefill_gpus:
        description: 'Number of GPUs for disaggregated prefill'
        required: true
        type: number
        default: 4
      hardware:
        description: 'Hardware type (e.g., H200, B200)'
        required: true
        type: string
        default: 'B200'
      precision:
        description: 'Precision (e.g., fp4, fp8)'
        required: true
        type: string
        default: 'fp4'
      speculation_tokens:
        description: 'Number of speculation/draft tokens'
        required: true
        type: number
        default: 5
      tokenizer:
        description: 'Tokenizer name (from ./tokenizers/ directory)'
        required: true
        type: string
        default: 'DeepSeek-V3'
      skip_generation:
        description: 'Skip generation tests'
        required: false
        type: boolean
        default: false
      skip_prefill:
        description: 'Skip prefill tests'
        required: false
        type: boolean
        default: false

jobs:
  benchmark:
    runs-on: ubuntu-latest

    steps:
      - name: Placeholder
        run: |
          echo "This is a skeleton workflow on main branch. TEMPORARY GHA."
          echo "Run this workflow from a feature branch with the full implementation."
          exit 0
